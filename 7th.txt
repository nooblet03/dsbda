import nltk 
nltk.download('omw-1.4')

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.tokenize import word_tokenize  
from nltk.corpus import stopwords  
from nltk.stem import PorterStemmer,WordNetLemmatizer
from nltk import pos_tag
from sklearn.feature_extraction.text import TfidfVectorizer

document = """My name is jack"""

token = word_tokenize(document)
token

postag = pos_tag(token)
postag

stopW = (stopwords.words('english'))
fil_token = [word for word in token if word.lower() not in stopW]
fil_token

stemmer = PorterStemmer()
stem_token = [stemmer.stem(word) for word in fil_token]
stem_token

lemmatizer = WordNetLemmatizer()
lemm_token =[lemmatizer.lemmatize(word) for word in fil_token]
lemm_token

processed_doc = ' '.join(lemm_token)
processed_doc 

tfidf_matrix = TfidfVectorizer().fit_transform([document])
tfidf_matrix.toarray()